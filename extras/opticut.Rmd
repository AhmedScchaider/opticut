---
title: 'opticut: likelihood based optimal partitioning for indicator species analysis'
author: "Peter Solymos et al."
date: "November 4, 2015"
output: pdf_document
---

# Introduction

General problem: find where species abundances are high vs low, leads to optimal classification of low vs high abundance strata.

Previous attempts: historical review (?), highlighting IndVal

Issues:

* summary statistics & Monte Carlo randomization, no model
* data types not always compatible with randomization (i.e. decimals)
* confounding effects to classification accuracy can impact power

Goals: 

* describe a general and extensible approach
* implement a computationally efficient algorithm
* tools for exploring the results (i.e. summaries, plots) in a OO framework

# Methods

## The quest for optimal binary partitioning

$Y_{i}$'s are observations for a single species
from $n$ locations ($i = 1, ..., n$).
$g_{i}$'s are known discrete descriptors of the locations with
$k$ levels ($k > 2$). $z^{(m)}$ is a binary reclassification of $g$ taking
values (0, 1). The superscript $m = 1, ..., M$ indicates a possible combination of binary reclassification out of the total $M = 2^{k-1} - 1$ total combinations (excluding complements). See below for options for defining binary partitions.
There can also be other site descriptors denoted as $x_{ij}$
taking discrete or continuous values ($j = 1, ..., p$; number of predictors).

A suitable parametric model describe the
relationship between the observations and the site decriptors
through the probability density function $P(Y = y | z, x, \theta)$ 
where $\theta$ is the vector of model parameters 
($\beta_{0}, \beta_{1}, \alpha_{1}, ..., \alpha_{p}$).
The choice of the parametric model depends on the nature of the 
observations. It can be Gaussian, Binomial, Poisson,
ordinal, Beta regression, or zero-inflated models, with a 
suitable link function ($f$) for the mean:
$f(\eta_{i}) = \beta_{0}^{(m)} + \beta_{1}^{(m)} z_{i}^{(m)} + \sum_{j=1}^{p} \alpha_{j}^{(m)} x_{ij}$.

$\hat{\theta}^{(m)}$ is the maximum likelihood estimate (MLE) of the 
model parameters given the data and classification $m$, 
with corresponding log-likelihood value $l(\hat{\theta}^{(m)}; y)$.
Finding MLEs for all $M$ candidate binary partitions
leads to a set of log-likelihood values. One can compare
the log-likelihood values to a null model (no binary partition is necessar)
where $\beta_{1} = 0$ leading to the MLE $\hat{\theta}^{(0)}$
and corresponding log-likelihood value for the null model: 
$l(\hat{\theta}^{(0)}; y)$.

The log-likelihood ratio for each cadidate partition can be
calculated as $l(\hat{\theta}^{(m)}; y) - l(\hat{\theta}^{(0)}; y)$.
The best supported binary partition is
the model with the highest log-likelihood ratio value.

The indicator value ($I$) for each candidate partition can be calculated
based on expected values using the inverse link function as 
$\mu_{0}^{(m)} = f^{-1}(\beta_{0}^{(m)})$ and 
$\mu_{1}^{(m)} = f^{-1}(\beta_{0}^{(m)} + \beta_{1}^{(m)})$.
$I = 1 - min(\mu_{0}^{(m)}, \mu_{1}^{(m)}) / max(\mu_{0}^{(m)}, \mu_{1}^{(m)})$.

## Finding all possible binary partitions

Finding all combinations does not require a model or observed responses.
It only takes a classification vector with $k > 1$ partitions.

`kComb` returns a 'contrast' matrix corresponding to
all possible binary partitions of the factor with `n` levels.
Complements are not counted twice, i.e.
(0,0,1,1) is equivalent to (1,1,0,0).
The number of such possible combinations is $2^{k-1} - 1$.

```{r, echo=FALSE}
source("~/repos/opticut/R/opticut.R")
#options("digits"=7)
```
```{r}
kComb(k = 2)
kComb(k = 3)
kComb(k = 4)
```

`allComb` this takes a classification vector with at least 2 levels
and returns a model matrix with binary partitions. `checkComb`
checks if combinations are unique and non-complementary
(misfits are returned as attributes).

```{r}
(f <- rep(LETTERS[1:4], each=2))
(mc <- allComb(f, collapse = "_"))
checkComb(mc)
mc2 <- cbind(z = 1 - mc[,1], mc[,c(1:ncol(mc), 1)])
colnames(mc2) <- 1:ncol(mc2)
mc2
checkComb(mc2)
```

## Poisson count model example

```{r}
set.seed(1234)
n <- 200
x0 <- sample(1:4, n, TRUE)
x1 <- ifelse(x0 %in% 1:2, 1, 0)
x2 <- rnorm(n, 0.5, 1)
table(x0,x1)
lam1 <- exp(0.5 + 0.5*x1 + -0.2*x2)
boxplot(lam1~x0)
Y1 <- rpois(n, lam1)
lam2 <- exp(0.1 + 0.5*ifelse(x0==4,1,0) + 0.2*x2)
boxplot(lam2~x0)
Y2 <- rpois(n, lam2)
lam3 <- exp(0.1 + -0.2*x2)
boxplot(lam3~x0)
Y3 <- rpois(n, lam3)
Y <- cbind(SPP1=Y1, SPP2=Y2, SPP3=Y3)
X <- model.matrix(~x2)
Z <- allComb(x0)
opticut1(Y1, X, Z, dist="poisson")
opticut1(Y2, X, Z, dist="poisson")
opticut1(Y3, X, Z, dist="poisson")
summary(opticut(Y ~ x2, strata=x0, dist="poisson", comb="all"))
```

Describe here what is what in the output.

## Not using all possible partitions

Blindly fitting a model to all possible partitions is wasteful
use of resources. Instead, one can rank the $k$ partitions
based on expected response values ($\mu_{1}, ..., \mu_{k}$)
and only explore $k-1$ partitions:

```{r}
oComb(1:4)
```

`oComb` return the 'contrast' matrix based on the rank vector as input.
Rank 1 means highest expected value among the partitions.

The function `rankComb` fits the model with multiple ($k > 2$) factor levels
to find out the ranking, and returns a binary classification matrix
similarly to `allComb`:

```{r}
head(rankComb(Y1, Z, as.factor(x0)))
```

Note that the ranking varies from species to species, thus
it is not possible to supply the resulting matrix as
`strata` definition:

```{r}
summary(opticut(Y ~ x2, strata=x0, dist="poisson", comb="rank"))
```

There is an overhead of fitting the model to calculate the ranking.
But computing efficiencies can be still high compared to all partitions
when the number of levels ($k$) is high.

## Distributions

Currently available distributions:

* `"gaussian"`: real valued continuous observations, e.g. biomass,
* `"poisson"`: Poisson count data,
* `"binomial"`: presence-absence type data,
* `"negbin"`: overdispersed Negative Binomial count data,
* `"beta"`: continuous response in the unit interval, e.g. percent cover,
* `"zip"`: zero-inflated Poisson counts,
* `"zinb"`: zero-inflated Negative Binomial counts,
* `"ordered"`: response measured on ordinal scale, e.g. ordinal vegetation cover, 
* `"rspf"`: presence-only data using resource selection probability functions.

The `distr` argument accepts a function, so other parametric models
can be supplied which are avoided due to package dependencies. 
It is possible to supply occupancy or N-mixture model
to account for detection error in the observations.
Here is an example using mixed models and the package `lme4`:

```{r}
library(lme4)
set.seed(1234)
n <- 200
x0 <- sample(1:4, n, TRUE)
x1 <- ifelse(x0 %in% 1:2, 1, 0)
x2 <- rnorm(n, 0.5, 1)
ee <- rnorm(n/5)
g <- rep(1:5, each=n/5)
lam1 <- exp(0.5 + 0.5*x1 + -0.2*x2 + ee[g])
Y1 <- rpois(n, lam1)

X <- model.matrix(~x2)
Z <- allComb(x0)

lmefun <- function(Y, X, linkinv, gr, ...) {
    X <- as.matrix(X)
    m <- glmer(Y ~ X-1 + (1|gr), family=poisson("log"), ...)
    list(coef=fixef(m),
        logLik=logLik(m),
        linkinv=family(m)$linkinv)
}
lmefun(Y1, X, gr=g)

opticut1(Y1, X, Z, dist=lmefun, gr=g)
```

### Gaussian

```{r}
Y <- rnorm(n, log(lam1) + 10, 0.5)
(mod <- opticut(Y ~ x2, strata=x0, dist="gaussian"))
```

### Binomial

```{r}
set.seed(1234)
n <- 1000
x0 <- sample(1:4, n, TRUE)
x1 <- ifelse(x0 %in% 1:2, 1, 0)
x2 <- rnorm(n, 0.5, 1)
table(x0,x1)
p1 <- plogis(0.5 + 0.5*x1 + -0.2*x2)
boxplot(p1~x0)
Y1 <- rbinom(n, 1, p1)
p2 <- plogis(0.1 + 0.5*ifelse(x0==4,1,0) + 0.2*x2)
boxplot(p2~x0)
Y2 <- rbinom(n, 1, p2)
Y <- cbind(SPP1=Y1, SPP2=Y2)
X <- model.matrix(~x2)
Z <- allComb(x0)

summary(opticut(Y ~ x2, strata=x0, dist="binomial"))
```

### Legendre example

```{r}
gr <- rep(1:5, each=5)
spp <- cbind(Species1=rep(c(4,6,5,3,2), each=5),
    Species2=c(rep(c(8,4,6), each=5), 4,4,2, rep(0,7)),
    Species3=rep(c(18,2,0,0,0), each=5))
dist="poisson"
Y <- spp[,1]
X <- matrix(1,25,1)
Z <- allComb(gr)

summary(mod <- opticut(spp ~ 1, strata=gr, dist="poisson"))
```

### Mite data set: high performance computing

See computing time diffs and plotting options.

```{r}
library(vegan)
data(mite)
data(mite.env)
mite.env$hab <- with(mite.env, interaction(Shrub, Topo, drop=TRUE))
summary(mod0 <- opticut(as.matrix(mite) ~ SubsDens, mite.env,
    strata=mite.env$hab, dist="poisson"))
plot(mod0)

system.time(aa <- opticut(as.matrix(mite) ~ 1, strata=mite.env$hab, dist="poisson", comb="rank"))
system.time(bb <- opticut(as.matrix(mite) ~ 1, strata=mite.env$hab, dist="poisson", comb="all"))

## sequential
system.time(opticut(as.matrix(mite) ~ 1, strata=mite.env$hab, dist="poisson"))
## parallel -- compare system times
library(parallel)
cl <- makeCluster(3)
system.time(opticut(as.matrix(mite) ~ 1, strata=mite.env$hab, dist="poisson", cl=cl))
stopCluster(cl)
## forking -- will not work on Windows
system.time(opticut(as.matrix(mite) ~ 1, strata=mite.env$hab, dist="poisson", cl=3))
```

### Dune data -- cover type info

See http://www.davidzeleny.net/anadat-r/doku.php/en:data:dune

```{r}
library(vegan)
data(dune)
data(dune.env)

## ordinal regr
## (when nlevels() < 3 use logistic regression instead !!!
Dune <- as.matrix(dune)
#Dune <- Dune[,apply(Dune, 2, function(z) length(unique(z)))>2]
x <- opticut(Dune ~ 1, strata=dune.env$Management, dist="ordered")
summary(x)

## Binarizing data
Dune <- ifelse(as.matrix(dune)>0,1,0)
x <- opticut(Dune ~ 1, strata=dune.env$Management, dist="binomial")
summary(x)

## Beta regression
Dune <- as.matrix(dune+0.5) / 10
x <- opticut(Dune ~ 1, strata=dune.env$Management, dist="beta")
summary(x)
```

### Presence-only data

```{r}
## presence-only data
## single species model only:
## because the used distr is different for
## each species by definition.

library(ResourceSelection)
## settings
n.used <- 1000
m <- 10
n <- n.used * m
set.seed(1234)
x <- data.frame(x0=as.factor(sample(1:3, n, replace=TRUE)),
    x1=rnorm(n), x2=runif(n))
cfs <- c(1, -0.5, 0.1, -1, 0.5)
## Logistic RSPF model
dd <- simulateUsedAvail(x, cfs, n.used, m, link="logit")

Y <- dd$status
X <- model.matrix(~ x1 + x2, dd)
Z <- allComb(as.integer(dd$x0))

(mod <- opticut1(Y, X, dd$x0, dist="rspf", m=0, B=0))
```

## Stratigraphy example

```{r}
library(rioja)
data(aber)
strat.plot(aber$spec, aber$ages$Depth, scale.percent=TRUE, y.rev=TRUE)

z <- as.factor(cut(aber$ages$Depth, 5))
ab <- as.matrix(aber$spec) / 100
ab[ab == 0] <- 0.0001
ab <- ab[,apply(ab, 2, max) > 0.05]

a <- opticut(ab ~ 1, strata=z, comb="rank", dist="beta")
summary(a)
bp <- bestpart(a)

op <- par(mfrow=c(3,4), mar=c(2,2,1,1))
for (i in 1:12) {
    plot(ab[,i], aber$ages$Depth, type="l", ann=FALSE)
    segments(x0=rep(0, nrow(ab)), y0=aber$ages$Depth, x1=ab[,i], 
        col=ifelse(bp[,i] > 0, 2, 1))
    title(main=colnames(ab)[i])
}
par(op)
```

## Finding best partitions

It is useful to access the best binary partition:

```{r}
bp <- bestpart(mod0)
head(bp)
```

The model based on the best partition can be returned as:

```{r}
bestmodel(mod0, which=1)
```

the `which` argument can be used to subset the species.

## Bootstrap

Uncertainty in $I$ values might be of interest:

```{r}
uc <- uncertainty(mod0)
i <- 1
summary(uc[[i]])
plot(density(uc[[i]]$I))
```


